## 公式

$$ Softmax(x_i)=\frac{\exp(x_i)}{\sum_j\exp(x_j)} $$

### 

### 参考

[CROSSENTROPYLOSS](https://pytorch.org/docs/master/generated/torch.nn.CrossEntropyLoss.html)
[Pytorch里的CrossEntropyLoss详解](https://www.cnblogs.com/marsggbo/p/10401215.html)

